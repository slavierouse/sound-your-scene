{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Explorer and Debugger\n",
    "\n",
    "This notebook provides comprehensive testing and debugging capabilities for the SoundByMood API backend.\n",
    "\n",
    "## Sections:\n",
    "1. **Direct Search Service Testing** - Manual testing of search functionality\n",
    "2. **Service Component Debugging** - Test music_service and llm_service individually\n",
    "3. **Storage Persistence Debugging** - Inspect in-memory storage state\n",
    "4. **End-to-End API Testing** - Full endpoint simulation with storage inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Direct Search Service Testing\n",
    "\n",
    "Manually test the search functionality without going through the API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing services...\n",
      "✅ Services initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Add API directory to path and import services\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../api')\n",
    "\n",
    "# Environment setup\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env', override=True)\n",
    "\n",
    "# Import services\n",
    "from music_service import MusicService\n",
    "from llm_service import LLMService\n",
    "from search_service import initialize_services\n",
    "\n",
    "# Initialize services\n",
    "music_service = MusicService()\n",
    "llm_service = LLMService()\n",
    "\n",
    "print(\"Initializing services...\")\n",
    "music_service.initialize('../data/main_df.csv')\n",
    "llm_service.initialize()\n",
    "print(\"✅ Services initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing query: 'brooding electronic music for coding'\n",
      "============================================================\n",
      "📝 Initial prompt: User query: brooding electronic music for coding\n",
      "Return ONLY JSON per schema.\n",
      "🤖 LLM Response:\n",
      "   User Message: I've set filters to find music that is less positive and energetic, and more instrumental with minimal vocals, fitting the 'brooding' and 'for coding' aspects. It's specifically tailored to electronic genres like EDM, ambient, house, and techno.\n",
      "   Reflection: The most important decisions were interpreting 'brooding' as low valence and low energy, and 'for coding' as highly instrumental with low speechiness to minimize distraction. 'Electronic music' was directly mapped to genre filters. Key filters set were: valence_max_decile to 4 and valence_decile_weight to -50; energy_max_decile to 5 and energy_decile_weight to -40; instrumentalness_min_decile to 7 and instrumentalness_decile_weight to 50; and speechiness_max_decile to 3 and speechiness_decile_weight to -50. Additionally, genre filters for electronic music were critical. To make this better, one could consider filtering by track popularity (e.g., views_min_decile) if the user implies wanting well-known tracks, or perhaps a slight negative weight for liveness to avoid live recordings if 'for coding' implies studio-quality focus.\n",
      "📊 Search Results:\n",
      "   Total Results: 0\n",
      "   Summary: {'result_count': 0}\n",
      "❌ No results found\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Manual query with auto-refinement simulation\n",
    "test_query = \"brooding electronic music for coding\"\n",
    "\n",
    "print(f\"🔍 Testing query: '{test_query}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Get initial LLM response\n",
    "initial_prompt = llm_service.create_initial_prompt(test_query)\n",
    "print(f\"📝 Initial prompt: {initial_prompt}\")\n",
    "\n",
    "filters_json = await llm_service.query_llm(initial_prompt)\n",
    "print(f\"🤖 LLM Response:\")\n",
    "print(f\"   User Message: {filters_json.get('user_message')}\")\n",
    "print(f\"   Reflection: {filters_json.get('reflection')}\")\n",
    "\n",
    "# Step 2: Apply filters and get results\n",
    "search_result = music_service.search(filters_json)\n",
    "results_df = search_result[\"results\"]\n",
    "summary = search_result[\"summary\"]\n",
    "\n",
    "print(f\"📊 Search Results:\")\n",
    "print(f\"   Total Results: {len(results_df)}\")\n",
    "print(f\"   Summary: {summary}\")\n",
    "\n",
    "# Step 3: Show top results\n",
    "if len(results_df) > 0:\n",
    "    top_5 = results_df.sort_values('relevance_score', ascending=False).head(5)\n",
    "    print(f\"🎵 Top 5 Results:\")\n",
    "    for idx, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "        print(f\"   {idx}. {row['track']} by {row['artist']} (Score: {row['relevance_score']:.1f})\")\n",
    "else:\n",
    "    print(\"❌ No results found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "🔍 Query: 'period drama soundtrack'\n",
      "📊 Results: 54 tracks\n",
      "💬 LLM: These filters are set to find music that sounds like a 'period drama soundtrack', focusing on instrumental tracks with high acoustic quality and a more calm, less danceable feel. We've specifically included genres like soundtrack, orchestra, and classical to ensure relevant results.\n",
      "\n",
      "========================================\n",
      "🔍 Query: 'upbeat pop for workout'\n",
      "📊 Results: 518 tracks\n",
      "💬 LLM: I've set filters to find upbeat pop music ideal for workouts by prioritizing high danceability, energy, and positive mood, along with a fast tempo. Pop genre tracks will also receive a relevance boost.\n",
      "\n",
      "========================================\n",
      "🔍 Query: 'jazz for late night study'\n",
      "📊 Results: 2 tracks\n",
      "💬 LLM: These filters are set to find instrumental jazz music that is calm and mellow, perfect for a focused late-night study session. They prioritize lower energy, minimal vocals, and a quieter, more acoustic sound.\n",
      "\n",
      "========================================\n",
      "🔍 Query: 'ambient instrumental background music'\n",
      "📊 Results: 175 tracks\n",
      "💬 LLM: These filters are set to find ambient and instrumental music suitable for background listening. They prioritize tracks with minimal vocals and high instrumental content, low energy, slow tempo, and generally non-explicit language.\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Try different queries\n",
    "test_queries = [\n",
    "    \"period drama soundtrack\",\n",
    "    \"upbeat pop for workout\",\n",
    "    \"jazz for late night study\",\n",
    "    \"ambient instrumental background music\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"🔍 Query: '{query}'\")\n",
    "    \n",
    "    try:\n",
    "        # Get LLM response\n",
    "        prompt = llm_service.create_initial_prompt(query)\n",
    "        filters = await llm_service.query_llm(prompt)\n",
    "        \n",
    "        # Get results\n",
    "        result = music_service.search(filters)\n",
    "        count = len(result[\"results\"])\n",
    "        \n",
    "        print(f\"📊 Results: {count} tracks\")\n",
    "        print(f\"💬 LLM: {filters.get('user_message', 'No message')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Service Component Debugging\n",
    "\n",
    "Test individual components of music_service and llm_service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Music Service Debugging\n",
    "print(\"🎵 MUSIC SERVICE DEBUGGING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test 1: Check dataset loading\n",
    "print(f\"📊 Dataset loaded: {music_service.main_df is not None}\")\n",
    "if music_service.main_df is not None:\n",
    "    print(f\"   Shape: {music_service.main_df.shape}\")\n",
    "    print(f\"   Columns: {list(music_service.main_df.columns[:10])}...\")  # First 10 columns\n",
    "\n",
    "# Test 2: Manual filter creation\n",
    "print(f\"\\n🔧 Testing manual filters...\")\n",
    "manual_filters = {\n",
    "    'danceability_min_decile': 5,\n",
    "    'danceability_max_decile': 10,\n",
    "    'danceability_decile_weight': 30,\n",
    "    'energy_min_decile': 7,\n",
    "    'energy_max_decile': 10,\n",
    "    'energy_decile_weight': 50,\n",
    "    'speechiness_min_decile': 1,\n",
    "    'speechiness_max_decile': 3,\n",
    "    'speechiness_decile_weight': -30,\n",
    "    'acousticness_min_decile': 1,\n",
    "    'acousticness_max_decile': 10,\n",
    "    'acousticness_decile_weight': 0,\n",
    "    'instrumentalness_min_decile': 7,\n",
    "    'instrumentalness_max_decile': 10,\n",
    "    'instrumentalness_decile_weight': 60,\n",
    "    'liveness_min_decile': 1,\n",
    "    'liveness_max_decile': 10,\n",
    "    'liveness_decile_weight': 0,\n",
    "    'valence_min_decile': 1,\n",
    "    'valence_max_decile': 10,\n",
    "    'valence_decile_weight': 0,\n",
    "    'views_min_decile': 1,\n",
    "    'views_max_decile': 10,\n",
    "    'views_decile_weight': 0,\n",
    "    'loudness_min': -60,\n",
    "    'loudness_max': 0,\n",
    "    'loudness_decile_weight': 0,\n",
    "    'tempo_min': 120,\n",
    "    'tempo_max': 140,\n",
    "    'tempo_decile_weight': 20,\n",
    "    'duration_ms_min': 30000,\n",
    "    'duration_ms_max': 600000,\n",
    "    'duration_ms_decile_weight': 0,\n",
    "    'album_release_year_min': 2010,\n",
    "    'album_release_year_max': 2025,\n",
    "    'track_is_explicit_min': 0,\n",
    "    'track_is_explicit_max': 1,\n",
    "    'spotify_artist_genres_include_any': 'electronic,edm',\n",
    "    'spotify_artist_genres_exclude_any': '',\n",
    "    'spotify_artist_genres_boosted': 'ambient,lo-fi',\n",
    "    'debug_tag': 'manual_test',\n",
    "    'reflection': 'Manual test filters',\n",
    "    'user_message': 'Testing manual filters'\n",
    "}\n",
    "\n",
    "# Test filter application\n",
    "filter_mask = music_service.llm_to_filters(manual_filters)\n",
    "print(f\"   Filter mask created: {type(filter_mask)}, {filter_mask.sum()} tracks match\")\n",
    "\n",
    "# Test results generation\n",
    "results_df = music_service.filters_to_results_df(filter_mask, manual_filters)\n",
    "print(f\"   Results generated: {len(results_df)} tracks with scores\")\n",
    "\n",
    "# Test summary creation\n",
    "summary = music_service.make_summary(results_df)\n",
    "print(f\"   Summary created: {list(summary.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Service Debugging\n",
    "print(\"🤖 LLM SERVICE DEBUGGING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test 1: Check client initialization\n",
    "print(f\"🔌 LLM client initialized: {llm_service.client is not None}\")\n",
    "\n",
    "# Test 2: Test prompt creation\n",
    "test_query = \"sad piano music\"\n",
    "initial_prompt = llm_service.create_initial_prompt(test_query)\n",
    "print(f\"\\n📝 Initial prompt created: {len(initial_prompt)} characters\")\n",
    "print(f\"   Preview: {initial_prompt[:100]}...\")\n",
    "\n",
    "# Test 3: Test refinement prompt\n",
    "dummy_filters = {'test': 'data'}\n",
    "dummy_summary = {'result_count': 100}\n",
    "refine_prompt = llm_service.create_refine_prompt(\n",
    "    original_query=test_query,\n",
    "    previous_filters=dummy_filters,\n",
    "    result_summary=dummy_summary,\n",
    "    user_feedback=\"make it more upbeat\"\n",
    ")\n",
    "print(f\"\\n🔄 Refinement prompt created: {len(refine_prompt)} characters\")\n",
    "print(f\"   Preview: {refine_prompt[:100]}...\")\n",
    "\n",
    "# Test 4: Test actual LLM call (if you want to test with real API)\n",
    "print(f\"\\n⚡ Testing LLM call...\")\n",
    "try:\n",
    "    llm_response = await llm_service.query_llm(initial_prompt)\n",
    "    print(f\"   ✅ LLM responded successfully\")\n",
    "    print(f\"   Response keys: {list(llm_response.keys())}\")\n",
    "    print(f\"   User message: {llm_response.get('user_message', 'None')}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ LLM call failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Storage Persistence Debugging\n",
    "\n",
    "Inspect and manipulate the in-memory storage state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 STORAGE DEBUGGING\n",
      "==================================================\n",
      "📊 Initial storage state:\n",
      "   JOB_STORE entries: 0\n",
      "   RESULT_STORE entries: 0\n",
      "\n",
      "🧪 Testing storage operations...\n",
      "   ✅ Job stored with ID: 7f703445...\n",
      "   ✅ Job retrieved: test query for storage\n",
      "   ✅ Job exists check: True\n",
      "\n",
      "📊 Storage state after test:\n",
      "   JOB_STORE entries: 1\n",
      "   Job IDs: ['7f703445-d6d0-4352-9d1e-d2fc7361c6e2']\n"
     ]
    }
   ],
   "source": [
    "# Storage Debugging\n",
    "import storage\n",
    "from models import JobData, JobStatus, ConversationHistory, RefinementStep\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "print(\"💾 STORAGE DEBUGGING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check initial state\n",
    "print(f\"📊 Initial storage state:\")\n",
    "print(f\"   JOB_STORE entries: {len(storage.JOB_STORE)}\")\n",
    "print(f\"   RESULT_STORE entries: {len(storage.RESULT_STORE)}\")\n",
    "\n",
    "# Create test job data\n",
    "test_job_id = str(uuid.uuid4())\n",
    "test_job_data = JobData(\n",
    "    status=JobStatus.QUEUED,\n",
    "    query_text=\"test query for storage\",\n",
    "    started_at=datetime.now(),\n",
    "    finished_at=None,\n",
    "    error_message=None,\n",
    "    conversation_history=None,\n",
    "    current_filters_json=None,\n",
    "    result_count=None\n",
    ")\n",
    "\n",
    "print(f\"\\n🧪 Testing storage operations...\")\n",
    "\n",
    "# Test store job\n",
    "storage.store_job(test_job_id, test_job_data)\n",
    "print(f\"   ✅ Job stored with ID: {test_job_id[:8]}...\")\n",
    "\n",
    "# Test retrieve job\n",
    "retrieved_job = storage.get_job(test_job_id)\n",
    "print(f\"   ✅ Job retrieved: {retrieved_job.query_text}\")\n",
    "\n",
    "# Test job exists\n",
    "exists = storage.job_exists(test_job_id)\n",
    "print(f\"   ✅ Job exists check: {exists}\")\n",
    "\n",
    "# Check storage state after operations\n",
    "print(f\"\\n📊 Storage state after test:\")\n",
    "print(f\"   JOB_STORE entries: {len(storage.JOB_STORE)}\")\n",
    "print(f\"   Job IDs: {list(storage.JOB_STORE.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conversation history storage\n",
    "print(\"💬 Testing conversation history storage...\")\n",
    "\n",
    "# Create test conversation history\n",
    "test_step = RefinementStep(\n",
    "    step_number=1,\n",
    "    step_type=\"initial\",\n",
    "    user_input=\"test query\",\n",
    "    filters_json={\"test\": \"filters\"},\n",
    "    result_count=42,\n",
    "    user_message=\"Test user message\",\n",
    "    rationale=\"Test rationale\",\n",
    "    result_summary={\"result_count\": 42},\n",
    "    timestamp=datetime.now(),\n",
    "    target_range=\"50-150\"\n",
    ")\n",
    "\n",
    "test_conversation = ConversationHistory(\n",
    "    original_query=\"test query\",\n",
    "    steps=[test_step],\n",
    "    current_step=1,\n",
    "    total_auto_refinements=0\n",
    ")\n",
    "\n",
    "# Update job with conversation history\n",
    "test_job_data.conversation_history = test_conversation\n",
    "storage.store_job(test_job_id, test_job_data)\n",
    "\n",
    "# Retrieve and verify\n",
    "updated_job = storage.get_job(test_job_id)\n",
    "print(f\"   ✅ Conversation history stored\")\n",
    "print(f\"   Steps: {len(updated_job.conversation_history.steps)}\")\n",
    "print(f\"   Original query: {updated_job.conversation_history.original_query}\")\n",
    "print(f\"   Step 1 message: {updated_job.conversation_history.steps[0].user_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CURRENT STORAGE STATE\n",
      "========================================\n",
      "📋 Jobs in storage: 1\n",
      "   🆔 7f703445... - queued - 'test query for storage'\n",
      "📊 Results in storage: 0\n"
     ]
    }
   ],
   "source": [
    "# Storage inspection utility\n",
    "def inspect_storage():\n",
    "    \"\"\"Utility function to inspect current storage state\"\"\"\n",
    "    print(\"🔍 CURRENT STORAGE STATE\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(f\"📋 Jobs in storage: {len(storage.JOB_STORE)}\")\n",
    "    for job_id, job_data in storage.JOB_STORE.items():\n",
    "        print(f\"   🆔 {job_id[:8]}... - {job_data.status.value} - '{job_data.query_text}'\")\n",
    "        if job_data.conversation_history:\n",
    "            steps = len(job_data.conversation_history.steps)\n",
    "            print(f\"      💬 {steps} conversation steps\")\n",
    "    \n",
    "    print(f\"📊 Results in storage: {len(storage.RESULT_STORE)}\")\n",
    "    for job_id, results in storage.RESULT_STORE.items():\n",
    "        print(f\"   🆔 {job_id[:8]}... - {results.result_count} total, {len(results.tracks)} tracks returned\")\n",
    "\n",
    "# Run inspection\n",
    "inspect_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 DEBUGGING SEARCH SERVICE\n",
      "==================================================\n",
      "Testing service initialization...\n",
      "   Music service main_df loaded: False\n",
      "   LLM service client loaded: False\n",
      "   ⚠️  Music service not initialized!\n",
      "   ✅ Music service initialized: True\n",
      "   ⚠️  LLM service not initialized!\n",
      "   ✅ LLM service initialized: True\n",
      "\n",
      "🤖 Testing LLM call...\n",
      "   ✅ LLM call successful: ['danceability_min_decile', 'danceability_max_decile', 'danceability_decile_weight', 'energy_min_decile', 'energy_max_decile', 'energy_decile_weight', 'speechiness_min_decile', 'speechiness_max_decile', 'speechiness_decile_weight', 'acousticness_min_decile', 'acousticness_max_decile', 'acousticness_decile_weight', 'instrumentalness_min_decile', 'instrumentalness_max_decile', 'instrumentalness_decile_weight', 'liveness_min_decile', 'liveness_max_decile', 'liveness_decile_weight', 'valence_min_decile', 'valence_max_decile', 'valence_decile_weight', 'views_min_decile', 'views_max_decile', 'views_decile_weight', 'loudness_min', 'loudness_max', 'loudness_decile_weight', 'tempo_min', 'tempo_max', 'tempo_decile_weight', 'duration_ms_min', 'duration_ms_max', 'duration_ms_decile_weight', 'album_release_year_min', 'album_release_year_max', 'track_is_explicit_min', 'track_is_explicit_max', 'spotify_artist_genres_include_any', 'spotify_artist_genres_exclude_any', 'spotify_artist_genres_boosted', 'debug_tag', 'reflection', 'user_message']\n",
      "\n",
      "🎵 Testing music search...\n",
      "   ✅ Music search successful: 18300 results\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Let's add error logging to find the issue\n",
    "import traceback\n",
    "\n",
    "print(\"🔧 DEBUGGING SEARCH SERVICE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test service initialization\n",
    "print(\"Testing service initialization...\")\n",
    "try:\n",
    "    from search_service import initialize_services, music_service, llm_service\n",
    "    print(f\"   Music service main_df loaded: {music_service.main_df is not \n",
    "None}\")\n",
    "    print(f\"   LLM service client loaded: {llm_service.client is not None}\")\n",
    "\n",
    "    # Test if services need initialization\n",
    "    if music_service.main_df is None:\n",
    "        print(\"   ⚠️  Music service not initialized!\")\n",
    "        music_service.initialize('../data/main_df.csv')\n",
    "        print(f\"   ✅ Music service initialized: {music_service.main_df is not \n",
    "None}\")\n",
    "\n",
    "    if llm_service.client is None:\n",
    "        print(\"   ⚠️  LLM service not initialized!\")\n",
    "        llm_service.initialize()\n",
    "        print(f\"   ✅ LLM service initialized: {llm_service.client is not \n",
    "None}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Service initialization error: {str(e)}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Test a simple LLM call\n",
    "print(f\"\\n🤖 Testing LLM call...\")\n",
    "try:\n",
    "    test_prompt = llm_service.create_initial_prompt(\"test music\")\n",
    "    test_response = await llm_service.query_llm(test_prompt)\n",
    "    print(f\"   ✅ LLM call successful: {list(test_response.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ LLM call failed: {str(e)}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Test music search\n",
    "print(f\"\\n🎵 Testing music search...\")\n",
    "try:\n",
    "    if 'test_response' in locals():\n",
    "        search_result = music_service.search(test_response)\n",
    "        print(f\"   ✅ Music search successful: {len(search_result['results'])} results\")\n",
    "    else:\n",
    "        print(\"   ⏭️  Skipping music search (no LLM response)\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Music search failed: {str(e)}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: End-to-End API Testing\n",
    "\n",
    "Simulate full API endpoint behavior with storage inspection at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 END-TO-END API TESTING\n",
      "==================================================\n",
      "🧹 Cleared storage for clean test\n",
      "📤 Testing POST /search endpoint simulation...\n",
      "   📋 Background task added: process_search_job\n",
      "   ✅ Job created with ID: c4caf0ab...\n",
      "   📋 Background tasks queued: 1\n",
      "🔍 Storage after job creation:\n",
      "🔍 CURRENT STORAGE STATE\n",
      "========================================\n",
      "📋 Jobs in storage: 1\n",
      "   🆔 c4caf0ab... - queued - 'period drama soundtrack'\n",
      "📊 Results in storage: 0\n"
     ]
    }
   ],
   "source": [
    "# End-to-End API Simulation\n",
    "from search_service import create_search_job, get_job_status, process_search_job\n",
    "from models import SearchRequest\n",
    "from fastapi import BackgroundTasks\n",
    "import asyncio\n",
    "\n",
    "print(\"🚀 END-TO-END API TESTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize services for search_service\n",
    "from search_service import initialize_services\n",
    "# Note: We've already initialized individual services above\n",
    "#initialize_services()\n",
    "\n",
    "\n",
    "# Clear storage for clean test\n",
    "storage.JOB_STORE.clear()\n",
    "storage.RESULT_STORE.clear()\n",
    "print(\"🧹 Cleared storage for clean test\")\n",
    "\n",
    "# Test 1: Simulate POST /search endpoint\n",
    "print(\"📤 Testing POST /search endpoint simulation...\")\n",
    "\n",
    "test_request = SearchRequest(query_text=\"period drama soundtrack\")\n",
    "\n",
    "# Mock BackgroundTasks (since we're not in FastAPI context)\n",
    "class MockBackgroundTasks:\n",
    "    def __init__(self):\n",
    "        self.tasks = []\n",
    "    \n",
    "    def add_task(self, func, *args, **kwargs):\n",
    "        self.tasks.append((func, args, kwargs))\n",
    "        print(f\"   📋 Background task added: {func.__name__}\")\n",
    "\n",
    "mock_bg_tasks = MockBackgroundTasks()\n",
    "\n",
    "# Call create_search_job\n",
    "response = await create_search_job(test_request, mock_bg_tasks)\n",
    "job_id = response[\"job_id\"]\n",
    "\n",
    "print(f\"   ✅ Job created with ID: {job_id[:8]}...\")\n",
    "print(f\"   📋 Background tasks queued: {len(mock_bg_tasks.tasks)}\")\n",
    "\n",
    "# Inspect storage after job creation\n",
    "print(\"🔍 Storage after job creation:\")\n",
    "inspect_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Testing GET /jobs/{id} endpoint (before processing)...\n",
      "   ✅ Job status retrieved\n",
      "   Status: JobStatus.QUEUED\n",
      "   Query: period drama soundtrack\n",
      "   Results: None\n",
      "   Conversation history: None\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Simulate GET /jobs/{id} endpoint (before processing)\n",
    "print(\"📥 Testing GET /jobs/{id} endpoint (before processing)...\")\n",
    "\n",
    "job_response = await get_job_status(job_id)\n",
    "print(f\"   ✅ Job status retrieved\")\n",
    "print(f\"   Status: {job_response.status}\")\n",
    "print(f\"   Query: {job_response.query_text}\")\n",
    "print(f\"   Results: {job_response.results}\")\n",
    "print(f\"   Conversation history: {job_response.conversation_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Simulating background job processing...\n",
      "   🏃 Executing: process_search_job with args ('c4caf0ab-7400-4b0f-9d18-a519df7c9359', 'period drama soundtrack')\n",
      "   ✅ Background processing completed\n",
      "🔍 Storage after background processing:\n",
      "🔍 CURRENT STORAGE STATE\n",
      "========================================\n",
      "📋 Jobs in storage: 1\n",
      "   🆔 c4caf0ab... - done - 'period drama soundtrack'\n",
      "      💬 3 conversation steps\n",
      "📊 Results in storage: 1\n",
      "   🆔 c4caf0ab... - 197 total, 50 tracks returned\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Simulate background job processing\n",
    "print(\"⚙️ Simulating background job processing...\")\n",
    "\n",
    "# Manually execute the background task\n",
    "if mock_bg_tasks.tasks:\n",
    "    func, args, kwargs = mock_bg_tasks.tasks[0]\n",
    "    print(f\"   🏃 Executing: {func.__name__} with args {args}\")\n",
    "    \n",
    "    # Execute the background processing\n",
    "    await func(*args, **kwargs)\n",
    "    \n",
    "    print(f\"   ✅ Background processing completed\")\n",
    "\n",
    "# Inspect storage after processing\n",
    "print(\"🔍 Storage after background processing:\")\n",
    "inspect_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Testing GET /jobs/{id} endpoint (after processing)...\n",
      "   ✅ Final job status retrieved\n",
      "   Status: JobStatus.DONE\n",
      "   Result count: 197\n",
      "   Has results: True\n",
      "   Has conversation history: True\n",
      "   📜 Conversation steps: 3\n",
      "   🔄 Auto refinements: 2\n",
      "      Step 1 (initial): 202 results\n",
      "         💬 These filters aim to find music that sounds like a 'period drama soundtrack' by prioritizing instrumental, acoustic, and classical-sounding tracks, while excluding modern, dance-oriented, or vocal-heavy genres.\n",
      "      Step 2 (auto_refine): 202 results\n",
      "         💬 These filters are refined to strongly prioritize instrumental, acoustic, and classical-style music typical of period drama soundtracks, by more strictly excluding upbeat, vocal, or overly cheerful tracks. We've also added a preference for slower tempos and boosted more popular tracks to enhance relevance and quality.\n",
      "      Step 3 (auto_refine): 197 results\n",
      "         💬 These refined filters more precisely target period drama soundtracks by strictly favoring slower tempos, lower energy, and more neutral to melancholic moods. We've also maintained a strong preference for acoustic, instrumental, and classical-style music to ensure high relevance.\n",
      "   🎵 Top 3 tracks:\n",
      "      1. Nocturne No. 2 In E Flat, Op. 9 No. 2 by Frédéric Chopin (Score: 6409387861.4)\n",
      "      2. Clair de Lune, L. 32 by Claude Debussy (Score: 2644725762.4)\n",
      "      3. Danse Macabre, Op. 40, R.171 by Camille Saint-Saëns (Score: 2124099726.3)\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Simulate GET /jobs/{id} endpoint (after processing)\n",
    "print(\"📥 Testing GET /jobs/{id} endpoint (after processing)...\")\n",
    "\n",
    "final_job_response = await get_job_status(job_id)\n",
    "print(f\"   ✅ Final job status retrieved\")\n",
    "print(f\"   Status: {final_job_response.status}\")\n",
    "print(f\"   Result count: {final_job_response.result_count}\")\n",
    "print(f\"   Has results: {final_job_response.results is not None}\")\n",
    "print(f\"   Has conversation history: {final_job_response.conversation_history is not None}\")\n",
    "\n",
    "if final_job_response.conversation_history:\n",
    "    history = final_job_response.conversation_history\n",
    "    print(f\"   📜 Conversation steps: {len(history.steps)}\")\n",
    "    print(f\"   🔄 Auto refinements: {history.total_auto_refinements}\")\n",
    "    \n",
    "    for i, step in enumerate(history.steps):\n",
    "        print(f\"      Step {i+1} ({step.step_type}): {step.result_count} results\")\n",
    "        print(f\"         💬 {step.user_message}\")\n",
    "\n",
    "if final_job_response.results:\n",
    "    results = final_job_response.results\n",
    "    print(f\"   🎵 Top 3 tracks:\")\n",
    "    for i, track in enumerate(results.tracks[:3]):\n",
    "        print(f\"      {i+1}. {track.track} by {track.artist} (Score: {track.relevance_score:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Testing error handling...\n",
      "   ✅ Correctly handled non-existent job: HTTPException\n",
      "🏁 End-to-end testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Error handling simulation\n",
    "print(\"❌ Testing error handling...\")\n",
    "\n",
    "# Test non-existent job\n",
    "fake_job_id = \"non-existent-job-id\"\n",
    "try:\n",
    "    await get_job_status(fake_job_id)\n",
    "    print(f\"   ❌ Should have failed for non-existent job\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✅ Correctly handled non-existent job: {type(e).__name__}\")\n",
    "\n",
    "print(\"🏁 End-to-end testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 FINAL STORAGE STATE\n",
      "==================================================\n",
      "🔍 CURRENT STORAGE STATE\n",
      "========================================\n",
      "📋 Jobs in storage: 1\n",
      "   🆔 c4caf0ab... - done - 'period drama soundtrack'\n",
      "      💬 3 conversation steps\n",
      "📊 Results in storage: 1\n",
      "   🆔 c4caf0ab... - 197 total, 50 tracks returned\n",
      "⚡ PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "   Job c4caf0ab... took 81.23 seconds\n",
      "      3 total steps, 2 auto-refinements\n"
     ]
    }
   ],
   "source": [
    "# Final storage inspection\n",
    "print(\"📊 FINAL STORAGE STATE\")\n",
    "print(\"=\"*50)\n",
    "inspect_storage()\n",
    "\n",
    "# Performance summary\n",
    "print(\"⚡ PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for job_id, job_data in storage.JOB_STORE.items():\n",
    "    if job_data.started_at and job_data.finished_at:\n",
    "        duration = job_data.finished_at - job_data.started_at\n",
    "        print(f\"   Job {job_id[:8]}... took {duration.total_seconds():.2f} seconds\")\n",
    "        if job_data.conversation_history:\n",
    "            steps = len(job_data.conversation_history.steps)\n",
    "            auto_refines = job_data.conversation_history.total_auto_refinements\n",
    "            print(f\"      {steps} total steps, {auto_refines} auto-refinements\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
